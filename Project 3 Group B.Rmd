---
title: "Project 3"
author: "Richard Xiao"
date: "2022-11-11"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(dplyr)
library(psych)
```

### Introduction section

This is an online news popularity data set, and dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict the number of shares in social networks (popularity). We're thinking about what kind of articles are we most likely to share, and we believe there are two aspects. One is objectivity. Users can feel the content is useful and valuable. The other one is subjectivity. Users agree with the attitudes expressed in the article, and also, the emotion expressed in the article resonated with users. 

Based on the two aspects, we choose 26 variables, and they are n_tokens_title, n_tokens_content, n_unique_tokens, num_imgs, num_videos, kw_avg_min, kw_max_max, kw_avg_max, kw_avg_avg, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday,. weekday_is_saturday, weekday_is_sunday, is_weekend, LDA_00: Closeness to LDA topic 0, global_subjectivity, global_sentiment_polarity, global_rate_positive_words, global_rate_negative_words, rate_positive_words, rate_negative_words, avg_positive_polarity, avg_negative_polarity.

We produce some basic analysis before we fitting the model. The purpose is to inspect the trends between different variables with respect to the number of share, and also, figure out the correlation between a few notable numeric variables. It helps the reader understand the summary or graph.

For a linear regression model, we'll use Backward stepwise and LASSO regression model. For an ensemble tree-based model, we'll fit random forest and boosted tree model.

## Testing


```{r cars}
df <- read_csv("./OnlineNewsPopularity.csv")
#Create a new variable for new data channel classification. Also want to remove the old data channel variables and other variables we don't need. Also want to rename the day variables to make it easier for analysis with rename variable.
df <- df %>%
  mutate(data_channel = if_else(
    data_channel_is_bus == 1,
    "Business",
    if_else(
      data_channel_is_entertainment == 1,
      "Entertainment",
      if_else(
        data_channel_is_lifestyle == 1,
        "Lifestyle",
        if_else(
          data_channel_is_socmed == 1,
          "Socmed",
          if_else(data_channel_is_tech == 1, "Tech", "World")
        )
      )
    )
  )) %>% 
  select(-c(url, timedelta, data_channel_is_bus, data_channel_is_entertainment,
            data_channel_is_socmed, data_channel_is_tech, data_channel_is_world,
            data_channel_is_lifestyle)) %>%
  mutate(log_shares = log(shares)) %>%
  select(-shares) %>% rename(monday = weekday_is_monday , tuesday = weekday_is_tuesday, wednesday = weekday_is_wednesday, thursday = weekday_is_thursday, friday = weekday_is_friday, saturday = weekday_is_saturday, sunday = weekday_is_sunday)
  
  
df_lifestyle <- df %>% filter(data_channel == "Lifestyle") 

lifestyle_index <- createDataPartition(df_lifestyle$log_shares, p = .7, list = FALSE)
lifestyle_train <- df_lifestyle[lifestyle_index,]
lifestyle_test <- df_lifestyle[-lifestyle_index,]

#This new dataframe converts the days into categorical values for graphing.

moddf_lifestyle1 <- lifestyle_train%>%
  mutate(day = if_else(monday == 1,"Monday",if_else(tuesday == 1,"Tuesday",if_else(wednesday == 1,"Wednesday",if_else(
thursday == 1,"Thursday",if_else(friday == 1,"Friday",if_else(saturday == 1,"Saturday", "Sunday")))))))

#Eliminates any categorical variables for use of principal component analysis
df_lifestylecontinuous <- lifestyle_train %>%select(-c(monday, tuesday, wednesday, thursday,friday, saturday, sunday, is_weekend, data_channel))


#Boxplot for log shares subdivided by days.

ggplot(moddf_lifestyle1, aes(x = day, y = log_shares, col = day)) + 
  geom_boxplot(fill="grey") + 
  geom_jitter() + 
  ylab("log(shares)") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 45)) +
  ggtitle("Boxplot for Log Shares by Day")

#Scatterplot for log shares and number of images
ggplot(moddf_lifestyle1, aes(y = log_shares, x = num_imgs, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("num_hrefs") + 
  ylab("log_shares")

#Scatterplot for log shares and number of videos.
ggplot(moddf_lifestyle1, aes(y = log_shares, x = num_videos, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("num_hrefs") + 
  ylab("log_shares")


#Histogram for log shares 
ggplot(moddf_lifestyle1, aes(x=log_shares, fill = kw_avg_avg, color = day)) + geom_histogram(binwidth = 1, position="dodge") + xlab("Average KeyWord") + ylab("Log Shares")

#Scatterplot for number of unique tokens and log shares
ggplot(moddf_lifestyle1, aes(y = log_shares, x = n_unique_tokens, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("n_unique_tokens") + 
  ylab("log_shares")

#Scatterplot for number of tokens content and log shares
ggplot(moddf_lifestyle1, aes(y = log_shares, x = n_tokens_content, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("n_tokens_content") + 
  ylab("log_shares")

#Scatterplot for number of token titles and log shares
ggplot(moddf_lifestyle1, aes(y = log_shares, x = n_tokens_title, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("n_tokens_title") + 
  ylab("log_shares")
```



```{r pressure, echo=FALSE}
#summary statistics for this continuous dataframe. Describe function is used to get statistics like sd, mean and other stats.
lifestyle_summarystats <-describe(df_lifestylecontinuous)
arrange_lifestylesummarystats <- lifestyle_summarystats %>%arrange(desc(sd))
```



```{r}
#Random forest model

#Select variables of interest for analysis.
lifestyle_analysis <- lifestyle_train %>% select(log_shares,num_imgs,num_videos,n_tokens_content,n_unique_tokens,n_tokens_title,kw_avg_min,kw_max_max,kw_avg_max,kw_avg_avg,global_subjectivity,global_sentiment_polarity,global_rate_positive_words,global_rate_negative_words,monday,tuesday,wednesday,thursday,friday,saturday,sunday)

fit_forest <- train(log_shares ~ ., data = lifestyle_analysis, method = "treebag",trControl = trainControl(method = "cv" , number = 10),preProcess = c("center", "scale"),mtry = c(1:21))

pred_forest <- predict(fit_forest, newdata = lifestyle_test)
postResample(pred_forest, lifestyle_test$log_shares)


```


```{r}
#Forward fitting model

fit_forward <- train(log_shares ~., data = lifestyle_analysis, preProcess = c("center", "scale"), method = "leapForward")

fit_forward_prediction <- predict(fit_forward, newdata = lifestyle_test)
postResample(fit_forward_prediction, lifestyle_test$log_shares)


```

```{r}
df_no_shares <- df_lifestylecontinuous %>%
  select(-log_shares)
#Creating PC's along with center and scaling variables
PCs <- prcomp(df_no_shares, center = TRUE, scale = TRUE)
#Creating screeplots
par(mfrow = c(1,2))
plot(PCs$sdev^2/sum(PCs$sdev^2), xlab = "Principal Component",
ylab = "Proportion of Variance Explained", ylim = c(0, 1), type = 'b')
plot(cumsum(PCs$sdev^2/sum(PCs$sdev^2)), xlab = "Principal Component",
ylab = "Cum. Prop of Variance Explained", ylim = c(0, 1), type = 'b')
#Selecting only the PC's up to a 80% variance explained threshold using caret
PCs_eighty <- preProcess(df_no_shares, method = c("center","scale", "pca"), thresh = .8)
#Creating a data frame with just my PC's, day variables, and log_shares to use later as a regression
df_PC <- predict(PCs_eighty, newdata = df_no_shares)
#Monday is excluded to avoid multicollinearity
df_PC <- df_PC %>%
  bind_cols(log_shares = df_lifestylecontinuous$log_shares,tuesday = lifestyle_train$tuesday, 
            wednesday = lifestyle_train$wednesday, thursday = lifestyle_train$thursday, friday = lifestyle_train$friday,
            saturday = lifestyle_train$saturday, sunday = lifestyle_train$sunday)
screeplot(PCs, type = "lines")
biplot(PCs)
```

### Modeling
```{r echo=TRUE,eval=TRUE}
library(tidyverse)
#Select variables of interest for analysis.
lifestyle_analysis <- lifestyle_train %>% select(log_shares,num_imgs,num_videos,n_tokens_content,n_unique_tokens,n_tokens_title,kw_avg_min,kw_max_max,kw_avg_max,kw_avg_avg,global_subjectivity,global_sentiment_polarity,global_rate_positive_words,global_rate_negative_words,monday,tuesday,wednesday,thursday,friday,saturday,sunday)
lifestyle_analysis
```

1. LASSO Regression Model
```{r echo=TRUE,eval=TRUE}
library(caret)
fitLASSO <- train(log_shares ~ ., data = lifestyle_analysis,
method = "lasso",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv", number = 10)
)
predLASSO <- predict(fitLASSO, newdata = lifestyle_test)
m1<-postResample(predLASSO, obs = lifestyle_test$log_shares)
m1
```
2. Boosted Tree Model
```{r echo=TRUE,eval=TRUE}
library(caret)
boostedFit <- train(log_shares ~ ., data = lifestyle_analysis, method = "gbm",trControl = trainControl(method = "cv" , number = 10),
                    preProcess = c("center", "scale"),
                    tuneGrid = expand.grid(n.trees = c(25, 50, 100, 150, 200),
                                           interaction.depth = 1:4,
                                           shrinkage = 0.1,
                                           n.minobsinnode = 10)
                    )
pred_boosted <- predict(boostedFit, newdata = lifestyle_test)
m2<-postResample(pred_boosted, lifestyle_test$log_shares)
m2
```
3.

4.
```{r}
#Random forest model
#Select variables of interest for analysis.
lifestyle_analysis <- lifestyle_train %>% select(log_shares,num_imgs,num_videos,n_tokens_content,n_unique_tokens,n_tokens_title,kw_avg_min,kw_max_max,kw_avg_max,kw_avg_avg,global_subjectivity,global_sentiment_polarity,global_rate_positive_words,global_rate_negative_words,monday,tuesday,wednesday,thursday,friday,saturday,sunday)
fit_forest <- train(log_shares ~ ., data = lifestyle_analysis, method = "treebag",trControl = trainControl(method = "cv" , number = 10),preProcess = c("center", "scale"),mtry = c(1:21))
pred_forest <- predict(fit_forest, newdata = lifestyle_test)
m4<-postResample(pred_forest, lifestyle_test$log_shares)
m4
```


### Comparison
```{r}
LASSO<- tibble(model = c("LASSO"), RMSE = c(m1[[1]]), Rsquared = c(m1[[2]]))

boostedTree<- tibble(model = c("boosted"), RMSE = c(m2[[1]]), Rsquared = c(m2[[2]]))


randomForest<- tibble(model = c("randomForest"), RMSE = c(m4[[1]]), Rsquared = c(m4[[2]]))

comparison<- rbind(LASSO, boostedTree, randomForest)
comparison
```

